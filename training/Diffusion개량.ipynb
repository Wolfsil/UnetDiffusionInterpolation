{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion개량\n",
    "1. 커스텀 학습대신 커스텀 데이터셋을 이용한 디퓨전 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "pathTrain=\"C:\\\\Users\\\\82109\\\\Desktop\\\\train\" #학습할 이미지 \n",
    "pathTest=\"C:\\\\Users\\\\82109\\\\Desktop\\\\test\" #벨리데이션 테스트 이미지\n",
    "#pathGeneratorTest=\"C:\\\\Users\\\\82109\\\\Desktop\\\\generatorTest\" #생성 테스트용 이미지\n",
    "pathSave=\"C:\\\\Users\\\\82109\\\\Desktop\\\\checkPoint\" #모델 저장할 위치\n",
    "batchSize=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 전처리 함수모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경로 반환\n",
    "def GetFilePath(path,end=\".gif\"):\n",
    "  gifFileList=os.listdir(path)\n",
    "  gifPath=[]\n",
    "  for name in gifFileList:\n",
    "    if name.endswith(tuple(end)):\n",
    "      gifPath.append(os.path.join(path,name))\n",
    "  return gifPath\n",
    "\n",
    "#못쓰는 데이터를 걸러줌\n",
    "def PreprocessGif(path,frame=5):\n",
    "  gif=Image.open(path)\n",
    "  targetFrame=gif.n_frames\n",
    "  targetSize=gif.size#이미지 크기가 너무크면 오버플로우 발생함\n",
    "  gif.close()\n",
    "  if targetSize[0]>targetSize[1]:\n",
    "    targetSize=targetSize[0]\n",
    "  else:\n",
    "    targetSize=targetSize[1]\n",
    "\n",
    "  if targetFrame<frame or targetSize>512:\n",
    "    print(path,\": \",targetFrame,\" \",targetSize,\"사용불가능\")\n",
    "    os.remove(path=path)\n",
    "  else:\n",
    "    print(path,\": \",targetFrame,\" \",targetSize,\" 사용가능\")\n",
    "\n",
    "\n",
    "#gif를 읽고 넘파이 배열로 노멀라이즈해줌\n",
    "def LoadGif(path, paddingSize=32):\n",
    "  gif=Image.open(path)\n",
    "  flip=np.random.randint(0,7)\n",
    "  extractFrame=np.random.randint(4,11)\n",
    "  remainFrame=gif.n_frames-extractFrame\n",
    "  start=0\n",
    "  end=0\n",
    "  if remainFrame<=1:\n",
    "    start=1\n",
    "    end=gif.n_frames\n",
    "  else:\n",
    "    start=np.random.randint(1,remainFrame+1)\n",
    "    end=start+extractFrame\n",
    "  images=[]\n",
    "  for i in range(start,end):\n",
    "    gif.seek(i)\n",
    "    temp=gif.transpose(flip).convert(\"RGBA\")\n",
    "    temp=np.array(temp)\n",
    "    height=(paddingSize-temp.shape[0]%paddingSize)%paddingSize\n",
    "    width=(paddingSize-temp.shape[1]%paddingSize)%paddingSize\n",
    "    temp=np.pad(temp, pad_width=((0,height),(0,width),(0,0)),mode=\"constant\",constant_values=0)\n",
    "    images.append(temp)\n",
    "  gif.close()\n",
    "  return np.array(images)/255.0\n",
    "\n",
    "\n",
    "def LoadGifAll(path, paddingSize=32):\n",
    "  gif=Image.open(path)\n",
    "  flip=np.random.randint(0,7)\n",
    "\n",
    "  images=[]\n",
    "  for i in range(1,gif.n_frames):\n",
    "    gif.seek(i)\n",
    "    temp=gif.transpose(flip).convert(\"RGBA\")\n",
    "    temp=np.array(temp)\n",
    "    height=(paddingSize-temp.shape[0]%paddingSize)%paddingSize\n",
    "    width=(paddingSize-temp.shape[1]%paddingSize)%paddingSize\n",
    "    temp=np.pad(temp, pad_width=((0,height),(0,width),(0,0)),mode=\"constant\",constant_values=0)\n",
    "    images.append(temp)\n",
    "  gif.close()\n",
    "  return np.array(images)/255.0\n",
    "\n",
    "\n",
    "#인풋데이터와 아웃풋 데이터를 분리\n",
    "def Divide(arr):\n",
    "  evens=arr[0::2]\n",
    "  odds=arr[1::2]\n",
    "  if evens.shape[0] != odds.shape[0]:\n",
    "    evens=evens[0:-1]\n",
    "  return [evens,odds]\n",
    "  \n",
    "def diffusionSchedule(diffusionTime):\n",
    "  startAng=np.arccos(0.99)\n",
    "  endAng=np.arccos(0.1)\n",
    "  diffusionAng=startAng+diffusionTime*(endAng-startAng) #DFT가 1에 가까울수록 노이즈(1에서 시작)\n",
    "  sigRate=np.cos(diffusionAng) # DFT가 1에 가까울수록 0.01\n",
    "  noiseRate=np.sin(diffusionAng) # DFT가 1에 가까울수록 0.99\n",
    "  return sigRate,noiseRate\n",
    "        \n",
    "  \n",
    "#데이터셋 제너레이터 생성\n",
    "def DatasetGenerater(gifPath):\n",
    "  #gif파일을 반환\n",
    "  for i in gifPath:\n",
    "      x,y= Divide(LoadGif(i))  \n",
    "      noise=np.random.rand(x.shape[0],x.shape[1],x.shape[2],x.shape[3])\n",
    "      step=np.ones((x.shape[0],x.shape[1],x.shape[2],1))\n",
    "      sigRate, noiseRate=diffusionSchedule(np.random.rand())\n",
    "      noisyImage=sigRate*y+noiseRate*noise\n",
    "      step=step*sigRate\n",
    "      yield np.concatenate([x,noisyImage,step],axis=-1),noise\n",
    "\n",
    "def saveGif(path, images):\n",
    "  imgs=[]\n",
    "  for i in images:\n",
    "    img=Image.fromarray((i*255).round().astype(np.int8), mode=\"RGBA\")\n",
    "    imgs.append(img)\n",
    "  imgs[0].save(path, save_all=True, append_images=imgs[1:], disposal = 2,duration=150, loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unet 모델 생성 함수모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperableConv(filter, input):\n",
    "    depthwise=tf.keras.layers.Conv3D(input.shape[-1],3,padding=\"same\",groups=input.shape[-1])(input)\n",
    "    pointwise=tf.keras.layers.Conv3D(filter,1,padding=\"same\")(depthwise)\n",
    "    return pointwise\n",
    "    \n",
    "def block(filter,input):\n",
    "    #conv1=tf.keras.layers.Conv3D(filter,3,padding=\"same\")(input)\n",
    "    conv1=seperableConv(filter,input)\n",
    "    layerNorm1=tf.keras.layers.LayerNormalization()(conv1)\n",
    "    swishAct1=tf.keras.layers.Activation(\"swish\")(layerNorm1)\n",
    "\n",
    "    #conv2=tf.keras.layers.Conv3D(filter,3,padding=\"same\")(swishAct1)\n",
    "    conv2=seperableConv(filter,swishAct1)\n",
    "    layerNorm2=tf.keras.layers.LayerNormalization()(conv2)\n",
    "    swishAct2=tf.keras.layers.Activation(\"swish\")(layerNorm2)\n",
    "    \n",
    "    return swishAct2\n",
    "\n",
    "def unetModel(inputShape=(None, None, None, 9)):\n",
    "    \n",
    "    inputImage=tf.keras.Input(shape=inputShape)\n",
    "\n",
    "    #인코딩\n",
    "    e1=block(32,inputImage)\n",
    "    e1Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e1)\n",
    "    \n",
    "    e2=block(64,e1Pooling)\n",
    "    e2Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e2)\n",
    "    \n",
    "    e3=block(128,e2Pooling)\n",
    "    e3Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e3)\n",
    "    \n",
    "    e4=block(256,e3Pooling)\n",
    "    e4Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e4)\n",
    "    \n",
    "    #중간\n",
    "    bottleNeck=block(512,e4Pooling)\n",
    "\n",
    "    \n",
    "    d4UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(bottleNeck)\n",
    "    d4Transpose=seperableConv(256,d4UpSampling)\n",
    "    d4Concatenate=tf.keras.layers.Concatenate()([d4Transpose,e4])\n",
    "    d4=block(256,d4Concatenate)\n",
    "    \n",
    "    d3UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d4)\n",
    "    d3Transpose=seperableConv(128,d3UpSampling)\n",
    "    d3Concatenate=tf.keras.layers.Concatenate()([d3Transpose,e3])\n",
    "    d3=block(128,d3Concatenate)\n",
    "    \n",
    "    d2UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d3)\n",
    "    d2Transpose=seperableConv(64,d2UpSampling)\n",
    "    d2Concatenate=tf.keras.layers.Concatenate()([d2Transpose,e2])\n",
    "    d2=block(64,d2Concatenate)\n",
    "    \n",
    "    d1UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d2)\n",
    "    d1Transpose=seperableConv(32,d1UpSampling)\n",
    "    d1Concatenate=tf.keras.layers.Concatenate()([d1Transpose,e1])\n",
    "    d1=block(32,d1Concatenate)\n",
    "    \n",
    "    outputImage=seperableConv(4,d1)\n",
    "    \n",
    "    return tf.keras.Model(inputImage,outputImage)\n",
    "unetModel().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습(학습할때만 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\")\n",
    "print(\"트레인셋 전처리\")\n",
    "#사용불가능 파일 전처리\n",
    "gifPath=GetFilePath(pathTrain) \n",
    "for i in gifPath:\n",
    "  PreprocessGif(i)\n",
    "gifPath=GetFilePath(pathTrain)\n",
    "\n",
    "print(\"\")\n",
    "print(\"총 트레인셋 갯수\",len(gifPath))\n",
    "\n",
    "print(\"\")\n",
    "print(\"테스트셋 전처리\")\n",
    "gifPathTest=GetFilePath(pathTest) \n",
    "for i in gifPathTest:\n",
    "  PreprocessGif(i)\n",
    "gifPathTest=GetFilePath(pathTest)\n",
    "\n",
    "print(\"\")\n",
    "print(\"총 테스트셋 갯수\",len(gifPathTest))\n",
    "\n",
    "\n",
    "trainDataset=tf.data.Dataset.from_generator(DatasetGenerater,\n",
    "                               args=[gifPath], output_types=(tf.float32,tf.float32),\n",
    "                               output_shapes = ((None, None,None,9),(None, None,None,4)))\n",
    "#(inputImages, outputImages)\n",
    "trainDataset=trainDataset.shuffle(5).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "testDataset=tf.data.Dataset.from_generator(DatasetGenerater,\n",
    "                               args=[gifPathTest], output_types=(tf.float32,tf.float32),\n",
    "                               output_shapes = ((None, None,None,9),(None, None,None,4)))\n",
    "#(inputImages, outputImages)\n",
    "testDataset=testDataset.shuffle(5).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델생성\n",
    "model=unetModel(inputShape=(None,None,None,9))\n",
    "model.load_weights(os.path.join(pathSave,\"1cp-0001.ckpt\"))\n",
    "#콜백생성\n",
    "cpCallback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(pathSave,\"cp-{epoch}.ckpt\"), \n",
    "    verbose=1, \n",
    "    save_weights_only=True)\n",
    "esCallback=tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "rlrCallback=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    min_lr=1e-5)\n",
    "\n",
    "#컴파일\n",
    "model.compile(\n",
    "    tf.keras.optimizers.experimental.AdamW(\n",
    "        learning_rate=1e-2, weight_decay=1e-4\n",
    "    ),\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    trainDataset,\n",
    "    epochs=10,\n",
    "    validation_data=testDataset,    \n",
    "    callbacks=[\n",
    "        cpCallback,\n",
    "        esCallback,\n",
    "        rlrCallback\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "field",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
