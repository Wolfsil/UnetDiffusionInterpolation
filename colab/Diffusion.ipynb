{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion\n",
    "1. 커스텀 학습 사용방식\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "pathTrain=\"C:\\\\Users\\\\82109\\\\Desktop\\\\train\" #학습할 이미지 \n",
    "pathTest=\"C:\\\\Users\\\\82109\\\\Desktop\\\\test\" #벨리데이션 테스트 이미지\n",
    "pathGeneratorTest=\"C:\\\\Users\\\\82109\\\\Desktop\\\\generatorTest\" #생성 테스트용 이미지\n",
    "pathSave=\"C:\\\\Users\\\\82109\\\\Desktop\\\\checkPoint\" #모델 저장할 위치\n",
    "batchSize=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#해당 디렉토리의 모든 파일명을 가져옴\n",
    "\n",
    "#경로 반환\n",
    "def GetFilePath(path,end=\".gif\"):\n",
    "  gifFileList=os.listdir(path)\n",
    "  gifPath=[]\n",
    "  for name in gifFileList:\n",
    "    if name.endswith(tuple(end)):\n",
    "      gifPath.append(os.path.join(path,name))\n",
    "  return gifPath\n",
    "\n",
    "#못쓰는 데이터를 걸러줌\n",
    "def PreprocessGif(path,frame=5):\n",
    "  gif=Image.open(path)\n",
    "  size=gif.n_frames\n",
    "  gif.close()\n",
    "  if size<frame:\n",
    "    print(path,\": \",size,\"사용불가능\")\n",
    "    os.remove(path=path)\n",
    "  else:\n",
    "    print(path,\": \",size,\" 사용가능\")\n",
    "\n",
    "#gif를 읽고 넘파이 배열로 노멀라이즈해줌\n",
    "def LoadGif(path, paddingSize=32):\n",
    "  gif=Image.open(path)\n",
    "  flip=np.random.randint(0,7)\n",
    "  extractFrame=np.random.randint(4,11)\n",
    "  remainFrame=gif.n_frames-extractFrame\n",
    "  start=0\n",
    "  end=0\n",
    "  if remainFrame<=1:\n",
    "    start=1\n",
    "    end=gif.n_frames\n",
    "  else:\n",
    "    start=np.random.randint(1,remainFrame+1)\n",
    "    end=start+extractFrame\n",
    "  images=[]\n",
    "  for i in range(start,end):\n",
    "    gif.seek(i)\n",
    "    temp=gif.transpose(flip).convert(\"RGBA\")\n",
    "    temp=np.array(temp)\n",
    "    height=(paddingSize-temp.shape[0]%paddingSize)%paddingSize\n",
    "    width=(paddingSize-temp.shape[1]%paddingSize)%paddingSize\n",
    "    temp=np.pad(temp, pad_width=((0,height),(0,width),(0,0)),mode=\"constant\",constant_values=0)\n",
    "    images.append(temp)\n",
    "  gif.close()\n",
    "  return np.array(images)/255.0\n",
    "\n",
    "#모든 프레임을 반환\n",
    "def LoadGifAll(path, paddingSize=32):\n",
    "  gif=Image.open(path)\n",
    "  flip=np.random.randint(0,7)\n",
    "\n",
    "  images=[]\n",
    "  for i in range(1,gif.n_frames):\n",
    "    gif.seek(i)\n",
    "    temp=gif.transpose(flip).convert(\"RGBA\")\n",
    "    temp=np.array(temp)\n",
    "    height=(paddingSize-temp.shape[0]%paddingSize)%paddingSize\n",
    "    width=(paddingSize-temp.shape[1]%paddingSize)%paddingSize\n",
    "    temp=np.pad(temp, pad_width=((0,height),(0,width),(0,0)),mode=\"constant\",constant_values=0)\n",
    "    images.append(temp)\n",
    "  gif.close()\n",
    "  return np.array(images)/255.0\n",
    "\n",
    "#인풋데이터와 아웃풋 데이터를 분리\n",
    "def Divide(arr):\n",
    "  evens=arr[0::2]\n",
    "  odds=arr[1::2]\n",
    "  if evens.shape[0] != odds.shape[0]:\n",
    "    evens=evens[0:-1]\n",
    "  return [evens,odds]\n",
    "\n",
    "  \n",
    "#데이터셋 제너레이터 생성\n",
    "def DatasetGenerater(gifPath):\n",
    "  #gif파일을 반환\n",
    "  for i in gifPath:\n",
    "      x1,y= Divide(LoadGif(i))  \n",
    "      x2=np.random.rand(x1.shape[0],x1.shape[1],x1.shape[2],x1.shape[3])\n",
    "      step=np.ones((x1.shape[0],x1.shape[1],x1.shape[2],1))\n",
    "      yield (x1,x2,step,y)\n",
    "\n",
    "def SaveGif(path, images):\n",
    "  imgs=[]\n",
    "  for i in images:\n",
    "    img=Image.fromarray((i*255).round().astype(np.int8), mode=\"RGBA\")\n",
    "    imgs.append(img)\n",
    "  imgs[0].save(path, save_all=True, append_images=imgs[1:], disposal = 2,duration=150, loop=0)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"트레인셋 전처리\")\n",
    "#사용불가능 파일 전처리\n",
    "gifPath=GetFilePath(pathTrain) \n",
    "for i in gifPath:\n",
    "  PreprocessGif(i)\n",
    "gifPath=GetFilePath(pathTrain)\n",
    "\n",
    "print(\"테스트셋 전처리\")\n",
    "gifPathTest=GetFilePath(pathTest) \n",
    "for i in gifPathTest:\n",
    "  PreprocessGif(i)\n",
    "gifPathTest=GetFilePath(pathTest)\n",
    "\n",
    "\n",
    "trainDataset=tf.data.Dataset.from_generator(DatasetGenerater,\n",
    "                               args=[gifPath], output_types=(tf.float32,tf.float32,tf.float32,tf.float32),\n",
    "                               output_shapes = ((None, None,None,4),(None, None,None,4),(None, None,None,1),(None, None,None,4)))\n",
    "#(inputImages, outputImages)\n",
    "trainDataset=trainDataset.shuffle(5).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "testDataset=tf.data.Dataset.from_generator(DatasetGenerater,\n",
    "                               args=[gifPathTest], output_types=(tf.float32,tf.float32,tf.float32,tf.float32),\n",
    "                               output_shapes = ((None, None,None,4),(None, None,None,4),(None, None,None,1),(None, None,None,4)))\n",
    "#(inputImages, outputImages)\n",
    "testDataset=testDataset.shuffle(5).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unet 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SeperableConv(filter, input):\n",
    "    depthwise=tf.keras.layers.Conv3D(input.shape[-1],3,padding=\"same\",groups=input.shape[-1])(input)\n",
    "    pointwise=tf.keras.layers.Conv3D(filter,1,padding=\"same\")(depthwise)\n",
    "    return pointwise\n",
    "    \n",
    "def Block(filter,input):\n",
    "    #conv1=tf.keras.layers.Conv3D(filter,3,padding=\"same\")(input)\n",
    "    conv1=SeperableConv(filter,input)\n",
    "    layerNorm1=tf.keras.layers.LayerNormalization()(conv1)\n",
    "    swishAct1=tf.keras.layers.Activation(\"swish\")(layerNorm1)\n",
    "\n",
    "    #conv2=tf.keras.layers.Conv3D(filter,3,padding=\"same\")(swishAct1)\n",
    "    conv2=SeperableConv(filter,swishAct1)\n",
    "    layerNorm2=tf.keras.layers.LayerNormalization()(conv2)\n",
    "    swishAct2=tf.keras.layers.Activation(\"swish\")(layerNorm2)\n",
    "    \n",
    "    return swishAct2\n",
    "\n",
    "\n",
    "def UnetModel(inputShape=(None, None, None, 4)):\n",
    "    \n",
    "    inputImage=tf.keras.Input(shape=inputShape)\n",
    "    noisyImage=tf.keras.Input(shape=inputShape)\n",
    "    step=tf.keras.Input(shape=(inputShape[0],inputShape[1],inputShape[2],1))\n",
    "    input=tf.keras.layers.Concatenate()([inputImage,noisyImage,step])\n",
    "    \n",
    "    #인코딩\n",
    "    e1=Block(32,input)\n",
    "    e1Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e1)\n",
    "    \n",
    "    e2=Block(64,e1Pooling)\n",
    "    e2Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e2)\n",
    "    \n",
    "    e3=Block(128,e2Pooling)\n",
    "    e3Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e3)\n",
    "    \n",
    "    e4=Block(256,e3Pooling)\n",
    "    e4Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e4)\n",
    "    \n",
    "    e5=Block(512,e4Pooling)\n",
    "    e5Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e5)\n",
    "    \n",
    "    #중간\n",
    "    bottleNeck=Block(1024,e5Pooling)\n",
    "\n",
    "    d5UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(bottleNeck)\n",
    "    d5Transpose=SeperableConv(512,d5UpSampling)\n",
    "    d5Concatenate=tf.keras.layers.Concatenate()([d5Transpose,e5])\n",
    "    d5=Block(512,d5Concatenate)\n",
    "    \n",
    "    d4UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d5)\n",
    "    d4Transpose=SeperableConv(256,d4UpSampling)\n",
    "    d4Concatenate=tf.keras.layers.Concatenate()([d4Transpose,e4])\n",
    "    d4=Block(256,d4Concatenate)\n",
    "    \n",
    "    d3UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d4)\n",
    "    d3Transpose=SeperableConv(128,d3UpSampling)\n",
    "    d3Concatenate=tf.keras.layers.Concatenate()([d3Transpose,e3])\n",
    "    d3=Block(128,d3Concatenate)\n",
    "    \n",
    "    d2UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d3)\n",
    "    d2Transpose=SeperableConv(64,d2UpSampling)\n",
    "    d2Concatenate=tf.keras.layers.Concatenate()([d2Transpose,e2])\n",
    "    d2=Block(64,d2Concatenate)\n",
    "    \n",
    "    d1UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d2)\n",
    "    d1Transpose=SeperableConv(32,d1UpSampling)\n",
    "    d1Concatenate=tf.keras.layers.Concatenate()([d1Transpose,e1])\n",
    "    d1=Block(32,d1Concatenate)\n",
    "    \n",
    "    outputImage=SeperableConv(4,d1)\n",
    "    \n",
    "    return tf.keras.Model([inputImage,noisyImage,step],outputImage)\n",
    "UnetModel().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디퓨전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiffusionModel(tf.keras.Model):\n",
    "    def __init__(self,network:tf.keras.Model,batchSize=1):\n",
    "        super().__init__()\n",
    "        self.network= network\n",
    "        self.batchSize=batchSize\n",
    "    \n",
    "    def train_step(self, images):\n",
    "\n",
    "        inputImages, noises, step, outputImages=images\n",
    "        diffusionTime = tf.random.uniform(\n",
    "            shape=(self.batchSize,1, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        sigRate, noiseRate= self.DiffusionSchedule(diffusionTime)\n",
    "        noisyImage = sigRate * outputImages + noiseRate * noises\n",
    "        step=step*sigRate\n",
    "        with tf.GradientTape() as tape:\n",
    "            predNoises=self.network([inputImages,noisyImage,step],training=True)\n",
    "            loss=self.compiled_loss(noises,predNoises)\n",
    "        gradients = tape.gradient(loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, images):\n",
    "        inputImages, noises, step, outputImages=images\n",
    "        diffusionTime = tf.random.uniform(\n",
    "            shape=(self.batchSize,1, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        sigRate, noiseRate= self.DiffusionSchedule(diffusionTime)\n",
    "        noisyImage = sigRate * outputImages + noiseRate * noises\n",
    "        step=step*sigRate\n",
    "        predNoises=self.network([inputImages,noisyImage,step],training=False)\n",
    "        loss=self.compiled_loss(noises,predNoises)\n",
    "        \n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def DiffusionSchedule(self, diffusionTime):\n",
    "        #각도가 줄어들음 (y축이 노이즈, x축이 시그널)\n",
    "        startAng=tf.acos(0.99) #  라디안 단위(180/파이), 약 0, 시그널 최대\n",
    "        endAng=tf.acos(0.01) # 약 90도, 노이즈 최대\n",
    "        \n",
    "        diffusionAng=startAng+diffusionTime*(endAng-startAng) #DFT가 1에 가까울수록 노이즈(1에서 시작)\n",
    "        sigRate=tf.cos(diffusionAng) # DFT가 1에 가까울수록 0.01\n",
    "        noiseRate=tf.sin(diffusionAng) # DFT가 1에 가까울수록 0.99\n",
    "        \n",
    "        return sigRate, noiseRate\n",
    "    \n",
    "\n",
    "    def Generator(self,inputImage:np.ndarray,diffusionStep=20):\n",
    "        #프레임, 높이, 넓이, 채널 형태의 이미지가 필요\n",
    "        if inputImage.shape[0]<2:\n",
    "            print(\"이미지 갯수가 부족합니다\")\n",
    "            return \n",
    "        inputImage=np.expand_dims(inputImage,axis=0)\n",
    "        stepSize=1.0 / diffusionStep\n",
    "\n",
    "        noisyImage=np.random.rand(1,inputImage.shape[0],inputImage.shape[1],inputImage.shape[2],inputImage.shape[3])\n",
    "        ones=np.ones((1,inputImage.shape[0],inputImage.shape[1],inputImage.shape[2],1))\n",
    "        for step in range(diffusionStep):\n",
    "            diffusionTime= 1.0 - step * stepSize\n",
    "            sigRate, noiseRate=self.DiffusionSchedule(diffusionTime)\n",
    "            sigRate=sigRates.numpy()\n",
    "            noiseRate=noiseRate.numpy()\n",
    "            step=sigRate*ones\n",
    "            predNoise=self.network.predict([inputImage, noisyImage, step])\n",
    "            predImage=(noisyImage-noiseRate*predNoise)/sigRates\n",
    "            \n",
    "            sigRates, noiseRate=self.DiffusionSchedule(diffusionTime-stepSize)\n",
    "            sigRates=sigRates.numpy()\n",
    "            noiseRate=noiseRate.numpy()\n",
    "            noisyImage=sigRates*predImage+noiseRate*predNoise\n",
    "            \n",
    "        \n",
    "        return np.clip(predImage[0], 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델생성\n",
    "network=UnetModel(inputShape=(None,None,None,4))\n",
    "model=DiffusionModel(network=network)\n",
    "#콜백생성\n",
    "cpCallback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=pathSave, \n",
    "    verbose=1, \n",
    "    save_weights_only=True)\n",
    "esCallback=tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "rlrCallback=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    min_lr=1e-5)\n",
    "\n",
    "#컴파일\n",
    "model.compile(\n",
    "    tf.keras.optimizers.experimental.AdamW(\n",
    "        learning_rate=1e-2, weight_decay=1e-4\n",
    "    ),\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    trainDataset,\n",
    "    epochs=20,\n",
    "    batch_size=1,\n",
    "    validation_data=testDataset,\n",
    "    validation_batch_size=1,\n",
    "    callbacks=[\n",
    "        cpCallback,\n",
    "        esCallback,\n",
    "        rlrCallback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#생성\n",
    "network.load_weights(\"model path\")#모델로드\n",
    "model=DiffusionModel(network=network)#모델장착\n",
    "\n",
    "randomVideo=np.random.rand(6,128,128,4)#이미지를 생성\n",
    "output=model.Generator(randomVideo)#생성\n",
    "SaveGif(\"gif path\",output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "field",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
