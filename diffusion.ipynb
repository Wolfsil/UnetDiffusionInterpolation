{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:\\\\Users\\\\82109\\\\Desktop\\\\datasets\"\n",
    "pathTest=\"C:\\\\Users\\\\82109\\\\Desktop\\\\datasetsval\"\n",
    "savePath=\"C:\\\\Users\\\\82109\\\\Desktop\\\\checkPoint\"\n",
    "batchSize=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#해당 디렉토리의 모든 파일명을 가져옴\n",
    "\n",
    "gifPath=[]\n",
    "#경로 반환\n",
    "def GetFilePath(path,end=\".gif\"):\n",
    "  gifFileList=os.listdir(path)\n",
    "  gifPath=[]\n",
    "  for name in gifFileList:\n",
    "    if name.endswith(tuple(end)):\n",
    "      gifPath.append(os.path.join(path,name))\n",
    "  return gifPath\n",
    "\n",
    "\n",
    "#못쓰는 데이터를 걸러줌\n",
    "def PreprocessGif(path,frame=5):\n",
    "  gif=Image.open(path)\n",
    "  size=gif.n_frames\n",
    "  gif.close()\n",
    "  if size<frame:\n",
    "    print(path,\": \",size,\"사용불가능\")\n",
    "    os.remove(path=path)\n",
    "  else:\n",
    "    print(path,\": \",size,\" 사용가능\")\n",
    "\n",
    "#gif를 읽고 넘파이 배열로 노멀라이즈해줌\n",
    "def LoadGif(path, paddingSize=32):\n",
    "  gif=Image.open(path)\n",
    "  flip=np.random.randint(0,7)\n",
    "  startCut=np.random.randint(1,gif.n_frames-3)#5  1~5\n",
    "\n",
    "  images=[]\n",
    "  for i in range(startCut,startCut+4):\n",
    "    gif.seek(i)\n",
    "    temp=gif.transpose(flip).convert(\"RGBA\")\n",
    "    temp=np.array(temp)\n",
    "    height=(paddingSize-temp.shape[0]%paddingSize)%paddingSize\n",
    "    width=(paddingSize-temp.shape[1]%paddingSize)%paddingSize\n",
    "    temp=np.pad(temp, pad_width=((0,height),(0,width),(0,0)),mode=\"constant\",constant_values=0)\n",
    "    images.append(temp)\n",
    "  gif.close()\n",
    "  return np.array(images)/255.0\n",
    "\n",
    "#인풋데이터와 아웃풋 데이터를 분리\n",
    "def Divide(arr):\n",
    "  evens=arr[0::2]\n",
    "  odds=arr[1::2]\n",
    "  if evens.shape[0] != odds.shape[0]:\n",
    "    evens=evens[0:-1]\n",
    "  return [evens,odds]\n",
    "\n",
    "#데이터셋 제너레이터 생성\n",
    "def DatasetGenerater(gifPath):\n",
    "  #gif파일을 반환\n",
    "  for i in gifPath:\n",
    "      x1,y=Divide(LoadGif(i))  \n",
    "      x2=np.random.rand(x1.shape[0],x1.shape[1],x1.shape[2],x1.shape[3])\n",
    "      yield (x1,x2,y)\n",
    "\n",
    "\n",
    "#사용예제 \n",
    "\n",
    "# gifPath=GetFilePath(path) \n",
    "# for i in gifPath:\n",
    "#   PreprocessGif(i)\n",
    "\n",
    "# arr=LoadGif(gifPath[3])\n",
    "# input, output=Divide(arr)\n",
    "# print(arr.shape ,input.shape, output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"트레인셋 전처리\")\n",
    "#사용불가능 파일 전처리\n",
    "gifPath=GetFilePath(path) \n",
    "for i in gifPath:\n",
    "  PreprocessGif(i)\n",
    "gifPath=GetFilePath(path)\n",
    "\n",
    "print(\"테스트셋 전처리\")\n",
    "gifPathTest=GetFilePath(pathTest) \n",
    "for i in gifPathTest:\n",
    "  PreprocessGif(i)\n",
    "gifPathTest=GetFilePath(pathTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset=tf.data.Dataset.from_generator(DatasetGenerater,\n",
    "                               args=[gifPath], output_types=(tf.float32,tf.float32,tf.float32),\n",
    "                               output_shapes = ((None, None,None,4),(None, None,None,4),(None, None,None,4)))\n",
    "#(inputImages, outputImages)\n",
    "trainDataset=trainDataset.shuffle(10).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "testDataset=tf.data.Dataset.from_generator(DatasetGenerater,\n",
    "                               args=[gifPathTest], output_types=(tf.float32,tf.float32,tf.float32),\n",
    "                               output_shapes = ((None, None,None,4),(None, None,None,4),(None, None,None,4)))\n",
    "#(inputImages, outputImages)\n",
    "testDataset=testDataset.shuffle(10).batch(batchSize).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testDataset:\n",
    "    print(i[0].shape[1]*i[0].shape[2]*i[0].shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unet 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seperableConv(filter, input):\n",
    "    depthwise=tf.keras.layers.Conv3D(input.shape[-1],3,padding=\"same\",groups=input.shape[-1])(input)\n",
    "    pointwise=tf.keras.layers.Conv3D(filter,1,padding=\"same\")(depthwise)\n",
    "    return pointwise\n",
    "    \n",
    "def block(filter,input):\n",
    "    #conv1=tf.keras.layers.Conv3D(filter,3,padding=\"same\")(input)\n",
    "    conv1=seperableConv(filter,input)\n",
    "    layerNorm1=tf.keras.layers.LayerNormalization()(conv1)\n",
    "    swishAct1=tf.keras.layers.Activation(\"swish\")(layerNorm1)\n",
    "\n",
    "    #conv2=tf.keras.layers.Conv3D(filter,3,padding=\"same\")(swishAct1)\n",
    "    conv2=seperableConv(filter,swishAct1)\n",
    "    layerNorm2=tf.keras.layers.LayerNormalization()(conv2)\n",
    "    swishAct2=tf.keras.layers.Activation(\"swish\")(layerNorm2)\n",
    "    \n",
    "    return swishAct2\n",
    "\n",
    "\n",
    "def unetModel(inputShape=(None, None, None, 4)):\n",
    "    inputImage=tf.keras.Input(shape=inputShape)\n",
    "    noisyImage=tf.keras.Input(shape=inputShape)\n",
    "    input=tf.keras.layers.Concatenate()([inputImage,noisyImage])\n",
    "    \n",
    "    #인코딩\n",
    "    e1=block(32,input)\n",
    "    e1Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e1)\n",
    "    \n",
    "    e2=block(64,e1Pooling)\n",
    "    e2Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e2)\n",
    "    \n",
    "    e3=block(128,e2Pooling)\n",
    "    e3Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e3)\n",
    "    \n",
    "    e4=block(256,e3Pooling)\n",
    "    e4Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e4)\n",
    "    \n",
    "    e5=block(512,e4Pooling)\n",
    "    e5Pooling=tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2))(e5)\n",
    "    \n",
    "    #중간\n",
    "    bottleNeck=block(1024,e5Pooling)\n",
    "\n",
    "    d5UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(bottleNeck)\n",
    "    d5Transpose=seperableConv(512,d5UpSampling)\n",
    "    d5Concatenate=tf.keras.layers.Concatenate()([d5Transpose,e5])\n",
    "    d5=block(512,d5Concatenate)\n",
    "    \n",
    "    d4UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d5)\n",
    "    d4Transpose=seperableConv(256,d4UpSampling)\n",
    "    d4Concatenate=tf.keras.layers.Concatenate()([d4Transpose,e4])\n",
    "    d4=block(256,d4Concatenate)\n",
    "    \n",
    "    d3UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d4)\n",
    "    d3Transpose=seperableConv(128,d3UpSampling)\n",
    "    d3Concatenate=tf.keras.layers.Concatenate()([d3Transpose,e3])\n",
    "    d3=block(128,d3Concatenate)\n",
    "    \n",
    "    d2UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d3)\n",
    "    d2Transpose=seperableConv(64,d2UpSampling)\n",
    "    d2Concatenate=tf.keras.layers.Concatenate()([d2Transpose,e2])\n",
    "    d2=block(64,d2Concatenate)\n",
    "    \n",
    "    d1UpSampling=tf.keras.layers.UpSampling3D(size=(1,2,2))(d2)\n",
    "    d1Transpose=seperableConv(32,d1UpSampling)\n",
    "    d1Concatenate=tf.keras.layers.Concatenate()([d1Transpose,e1])\n",
    "    d1=block(32,d1Concatenate)\n",
    "    \n",
    "    outputImage=seperableConv(4,d1)\n",
    "    \n",
    "    return tf.keras.Model([inputImage,noisyImage],outputImage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디퓨전 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_signal_rate = 0.01 #각도가 줄어들음 (y축이 노이즈, x축이 시그널)\n",
    "max_signal_rate = 0.99\n",
    "def diffusionSchedule(diffusionTime):\n",
    "    startAng=tf.acos(min_signal_rate) #라디안 단위(180/파이)\n",
    "    endAng=tf.acos(max_signal_rate) \n",
    "    diffusionAng=startAng+diffusionTime*(endAng-startAng)\n",
    "    sigRate=tf.cos(diffusionAng)\n",
    "    noiseRate=tf.sin(diffusionAng)\n",
    "    \n",
    "    return sigRate, noiseRate\n",
    "\n",
    "print(tf.acos(0.01).numpy(),tf.acos(0.99).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusionTime = tf.random.uniform(\n",
    "            shape=(1,10, 1024, 1024, 1), minval=10, maxval=20\n",
    ")\n",
    "diffusionTime2 = tf.random.uniform(\n",
    "    shape=(1,10,1024,1024, 4), minval=0.0, maxval=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(tf.keras.Model):\n",
    "    def __init__(self,network:tf.keras.Model,batchSize=1):\n",
    "        super().__init__()\n",
    "        self.network= network\n",
    "        self.batchSize=batchSize\n",
    "        \n",
    "    \n",
    "    def train_step(self, images):\n",
    "        print(0)\n",
    "        inputImages, noises, outputImages=images\n",
    "        #학습할 노이즈 생성\n",
    "        \n",
    "        diffusionTime = tf.random.uniform(\n",
    "            shape=(1,1, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noiseRates, sigRates = diffusionSchedule(diffusionTime)\n",
    "        noisyImage = sigRates * outputImages + noiseRates * noises\n",
    "        \n",
    "        print(1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            predinputImages=self.network([inputImages,noisyImage],training=True)\n",
    "            loss=self.compiled_loss(noises,predinputImages)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
    "        print(3)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "        \n",
    "    def test_step(self, images):\n",
    "        inputImages, outputImages=images\n",
    "        \n",
    "        #학습할 노이즈 생성\n",
    "        noises = tf.random.normal(\n",
    "            shape=(self.batchSize, inputImages.shape[1], inputImages.shape[2], inputImages.shape[3],inputImages.shape[4])\n",
    "            )\n",
    "        diffusionTime = tf.random.uniform(\n",
    "            shape=(1,1, 1, 1, 1), minval=0.0, maxval=1.0\n",
    "        )\n",
    "        noiseRates, sigRates = diffusionSchedule(diffusionTime)\n",
    "        noisyImage = sigRates * outputImages + noiseRates * noises\n",
    " \n",
    "        predinputImages=self.network([inputImages,noisyImage],training=False)\n",
    "        loss=self.compiled_loss(noises,predinputImages)\n",
    "\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델생성\n",
    "network=unetModel(inputShape=(None,None,None,4))\n",
    "model=DiffusionModel(network)\n",
    "\n",
    "#콜백생성\n",
    "cpCallback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=savePath, \n",
    "    verbose=1, \n",
    "    save_weights_only=True)\n",
    "esCallback=tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "rlrCallback=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    min_lr=1e-5)\n",
    "\n",
    "#컴파일\n",
    "model.compile(\n",
    "    tf.keras.optimizers.experimental.AdamW(\n",
    "        learning_rate=1e-2, weight_decay=1e-4\n",
    "    ),\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainDataset,epochs=100,batch_size=1, callbacks=[cpCallback,esCallback,rlrCallback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스낵코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.evalu\n",
    "\n",
    "savePath=\"C:\\Users\\82109\\Desktop\\checkPoint\\test.ckpt\"\n",
    "\n",
    "model=unetModel(inputShape=(None,None,None,4)) model.save_weights(filepath=savePath)\n",
    "\n",
    "model=unetModel(inputShape=(None,None,None,4)) model.load_weights(filepath=savePath)\n",
    "\n",
    "model=unetModel(inputShape=(None,None,None,4)) model.load_weights(filepath=savePath)\n",
    "\n",
    "unetModel().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "field",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
